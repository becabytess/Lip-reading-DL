{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "data_pth = '../datasets'\n",
    "videos_pth = os.path.join(data_pth,'videos')\n",
    "aligns_pth = os.path.join(data_pth,'alignments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = os.listdir(videos_pth)\n",
    "video_batches: list[str] =[ os.path.join(videos_pth,speaker) for speaker in speakers] \n",
    "align_batches = [os.path.join(aligns_pth,speaker) for speaker in speakers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []\n",
    "aligns = []\n",
    "for video_batch,align_batch in zip(video_batches,align_batches):\n",
    "    video_files = os.listdir(video_batch)\n",
    "    align_files = os.listdir(align_batch)\n",
    "    for video_file in video_files:\n",
    "        if not video_file.endswith('.mpg'):\n",
    "            continue\n",
    "        video_name = video_file.replace('.mpg','')\n",
    "        align_name = video_name + '.align'\n",
    "        align_path = os.path.join(align_batch,align_name)\n",
    "        \n",
    "        try:\n",
    "            with open(align_path , 'r') as f:\n",
    "                text = f.read()\n",
    "            if len(text) < 1:\n",
    "                continue\n",
    "        except:\n",
    "            print('align not found:',align_path)\n",
    "            continue    \n",
    "\n",
    "        videos.append(os.path.join(video_batch,video_file))\n",
    "        aligns.append(os.path.join(align_batch,align_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = 'abcdefghijklmnopqrstuvwxyz- '\n",
    "vocab_size = len(vocab)\n",
    "vti: dict[str, int] = {vocab[i]:i+1 for i in range(vocab_size)}\n",
    "vti['-']=0\n",
    "itv = {i:j for j,i in vti.items()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "def extract_frames(video):\n",
    "    frames: list[Any] = []\n",
    "    \n",
    "    cap = cv2.VideoCapture(video)\n",
    "\n",
    "    while True :\n",
    "        res , frame = cap.read()\n",
    "        if not res:\n",
    "            break \n",
    "        \n",
    "        frames.append(frame) \n",
    "    return np.stack(frames) \n",
    "\n",
    "    \n",
    "def extract_text(align):\n",
    "    with open(align, 'r') as f:\n",
    "        text = f.read()\n",
    "    text = ''.join(char for char in text if char in vocab)\n",
    "    return [vti[char] for char in text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(videos,aligns,test_size=0.2,random_state=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X,y,batch_size=4):\n",
    "    assert len(X)==len(y), \"\"\"X and y must be of the same size\"\"\"\n",
    "    idxs = np.random.randint(0,len(X),batch_size)\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for idx in idxs:\n",
    "        xs.append(X[idx])\n",
    "        ys.append(y[idx])\n",
    "    return np.stack([extract_frames(video) for video in xs]),[extract_text(align) for align in ys]\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs,ys = get_batch(X_train,y_train)\n",
    "# ys.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_channels,frames,height,width,hidden_size=100) -> None:\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "        self.height  = height \n",
    "        self.frames = frames \n",
    "        self.in_channels= in_channels\n",
    "        self.conv = nn.Sequential(\n",
    "        torch.nn.Conv3d(in_channels=in_channels,out_channels=16,kernel_size=(3,3,3),stride=(1,1,1),padding=(1,1,1)),\n",
    "        torch.nn.MaxPool3d(kernel_size=(1,2,2),stride=(1,2,2),padding=(0,0,0))  ,       \n",
    "        torch.nn.Conv3d(in_channels=16,out_channels=32,kernel_size=(3,3,3),stride=(1,1,1),padding=(1,1,1)),\n",
    "        torch.nn.MaxPool3d(kernel_size=(1,2,2),stride=(1,2,2),padding=(0,0,0)),\n",
    "        torch.nn.Conv3d(in_channels=32,out_channels=64,kernel_size=(3,3,3),stride=(1,1,1),padding=(1,1,1)),\n",
    "        torch.nn.MaxPool3d(kernel_size=(1,2,2),stride=(1,2,2),padding=(0,0,0)))\n",
    "        self.hidden_size = hidden_size\n",
    "        #b,c,f,h,w \n",
    "        inp_shape: Any = (width//8)*(height//8)*64\n",
    "        self.forget =nn.Sequential( nn.Linear( in_features=inp_shape + hidden_size,out_features= hidden_size),\n",
    "                                    nn.Sigmoid()  # Sigmoid activation function\n",
    "        )\n",
    "        \n",
    "        self.candidate =nn.Sequential( nn.Linear(in_features=hidden_size + inp_shape ,out_features=hidden_size),\n",
    "                                      nn.Tanh())\n",
    "    \n",
    "        self.input =nn.Sequential( nn.Linear(in_features=hidden_size + inp_shape,out_features=hidden_size),nn.Sigmoid()  # Sigmoid activation function\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(hidden_size+inp_shape,300),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(300,400),\n",
    "            \n",
    "            nn.Tanh(),\n",
    "            \n",
    "            nn.Linear(400,hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "                                    nn.Tanh()\n",
    "                                    \n",
    "                                    )\n",
    "        \n",
    "       \n",
    "\n",
    "        self.f = nn.Linear(2*hidden_size,out_features=vocab_size)\n",
    "    \n",
    "    def bidirectional(self, X, isbackward=False):\n",
    "        conv_out = self.conv(X).contiguous()\n",
    "        # print(conv_out.shape)\n",
    "        b, c, f, h, w = conv_out.size()\n",
    "        conv_out = conv_out.view(b, f, -1)\n",
    "        cell_state = torch.zeros(b, self.hidden_size, device=X.device)\n",
    "        hidden_state = torch.zeros(b, f, self.hidden_size, device=X.device)\n",
    "        outs = torch.zeros(b, f, vocab_size, device=X.device)\n",
    "        for t in (range(f-1, -1, -1) if isbackward else range(f)):\n",
    "\n",
    "            xt = conv_out[:, t, :]\n",
    "            prev_idx = t+1 if isbackward else t-1\n",
    "            valid_prev = (prev_idx >= 0 and prev_idx < f)\n",
    "            prev_hs = hidden_state[:, prev_idx, :] if valid_prev else torch.zeros(b, self.hidden_size, device=X.device)\n",
    "\n",
    "            # print(xt.shape)\n",
    "            # print(xt)\n",
    "            xt = torch.cat([xt, prev_hs], 1)\n",
    "            # print(xt.shape)\n",
    "\n",
    "            forget = self.forget(xt)\n",
    "\n",
    "            # print('forget passed')\n",
    "            input = self.input(xt)\n",
    "            # print('input passed')\n",
    "            candidate = self.candidate(xt)\n",
    "            # print('candidate passed')\n",
    "            output = self.output(xt)\n",
    "            new_cell_state = forget * cell_state + input * candidate\n",
    "            # print('new_cell_state passed')\n",
    "            new_hidden_state = output * torch.tanh(input=new_cell_state)\n",
    "            \n",
    "            cell_state = new_cell_state\n",
    "            hidden_state[:, t, :] = new_hidden_state\n",
    "\n",
    "        return hidden_state\n",
    "\n",
    "    def forward(self, X):\n",
    "        forward_outs = self.bidirectional(X)\n",
    "        backward_outs = self.bidirectional(X, isbackward=True)\n",
    "\n",
    "        hidden_state = torch.cat([forward_outs, backward_outs], 2)\n",
    "        outs = self.f(hidden_state)\n",
    "        \n",
    "        # Ensure numerical stability in log_softmax\n",
    "        return nn.functional.log_softmax(outs, dim=2)\n",
    "            \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xs,ys = get_batch(X_train,y_train)\n",
    "Xs = torch.tensor(Xs).float()\n",
    "Xs = Xs.permute(0,4,1,2,3)\n",
    "Xs = Xs / 255.0\n",
    "model = Model(in_channels=3,frames=75,height=Xs.shape[3],width=Xs.shape[4])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "Xs = Xs.to(device)\n",
    "\n",
    "# Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "yts =torch.cat( [ torch.tensor(yi) for  yi in ys])\n",
    "# len(yts)\n",
    "yts = yts.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shapes:\n",
      "Xs shape: torch.Size([4, 3, 75, 288, 360])\n",
      "Predictions shape before permute: torch.Size([4, 75, 28])\n",
      "Predictions shape after permute: torch.Size([75, 4, 28])\n"
     ]
    }
   ],
   "source": [
    "target_lengths = torch.tensor([len(yi) for yi in ys]).to(device)\n",
    "input_lengths = torch.tensor([72 for _ in range(len(ys))]).to(device)\n",
    "\n",
    "print(\"Input shapes:\")\n",
    "print(f\"Xs shape: {Xs.shape}\")\n",
    "print(f\"Predictions shape before permute: {model(Xs).shape}\")\n",
    "print(f\"Predictions shape after permute: {model(Xs).permute(1,0,2).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(target_lengths[i] <= input_lengths[i] for i in range(len(input_lengths)))\n",
    "# input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 , loss: 4.348903656005859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12771/890081209.py:14: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(),max_norm=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 , loss: 4.3899617195129395\n",
      "epoch:2 , loss: 3.9921717643737793\n",
      "epoch:3 , loss: 3.6761672496795654\n",
      "epoch:4 , loss: 3.408346176147461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 , loss: 3.2136080265045166\n",
      "epoch:6 , loss: 3.0822715759277344\n",
      "epoch:7 , loss: 3.00744891166687\n",
      "epoch:8 , loss: 2.93611741065979\n",
      "epoch:9 , loss: 2.8645260334014893\n",
      "epoch:10 , loss: 2.807953357696533\n",
      "epoch:11 , loss: 2.7496933937072754\n",
      "epoch:12 , loss: 2.691725254058838\n",
      "epoch:13 , loss: 2.641314744949341\n",
      "epoch:14 , loss: 2.5985398292541504\n",
      "epoch:15 , loss: 2.5616064071655273\n",
      "epoch:16 , loss: 2.533553123474121\n",
      "epoch:17 , loss: 2.499467134475708\n",
      "epoch:18 , loss: 2.467519760131836\n",
      "epoch:19 , loss: 2.436652421951294\n",
      "epoch:20 , loss: 2.409245252609253\n",
      "epoch:21 , loss: 2.387781858444214\n",
      "epoch:22 , loss: 2.371035575866699\n",
      "epoch:23 , loss: 2.356872081756592\n",
      "epoch:24 , loss: 2.34299635887146\n",
      "epoch:25 , loss: 2.3267741203308105\n",
      "epoch:26 , loss: 2.3124356269836426\n",
      "epoch:27 , loss: 2.3017921447753906\n",
      "epoch:28 , loss: 2.288360834121704\n",
      "epoch:29 , loss: 2.272719621658325\n",
      "epoch:30 , loss: 2.2620315551757812\n",
      "epoch:31 , loss: 2.2532238960266113\n",
      "epoch:32 , loss: 2.2466378211975098\n",
      "epoch:33 , loss: 2.2469658851623535\n",
      "epoch:34 , loss: 2.244014263153076\n",
      "epoch:35 , loss: 2.2388572692871094\n",
      "epoch:36 , loss: 2.2301461696624756\n",
      "epoch:37 , loss: 2.2248709201812744\n",
      "epoch:38 , loss: 2.226388692855835\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n",
      "Invalid loss detected: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs): \n\u001b[0;32m----> 5\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m      6\u001b[0m     preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ctc_loss(preds, yts, input_lengths, target_lengths)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[103], line 98\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     97\u001b[0m     forward_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional(X)\n\u001b[0;32m---> 98\u001b[0m     backward_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misbackward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     hidden_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([forward_outs, backward_outs], \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    101\u001b[0m     outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(hidden_state)\n",
      "Cell \u001b[0;32mIn[103], line 84\u001b[0m, in \u001b[0;36mModel.bidirectional\u001b[0;34m(self, X, isbackward)\u001b[0m\n\u001b[1;32m     82\u001b[0m candidate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidate(xt)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# print('candidate passed')\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m new_cell_state \u001b[38;5;241m=\u001b[39m forget \u001b[38;5;241m*\u001b[39m cell_state \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m candidate\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# print('new_cell_state passed')\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py:2546\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2544\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2545\u001b[0m     )\n\u001b[0;32m-> 2546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ctc_loss = nn.CTCLoss(blank=0,zero_infinity=True) \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "epochs = 300\n",
    "for epoch in range(epochs): \n",
    "    preds = model(Xs)    \n",
    "    preds = preds.permute(1,0,2).to(device)\n",
    "\n",
    "    loss = ctc_loss(preds, yts, input_lengths, target_lengths)\n",
    "    \n",
    "    if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "        print(f'epoch:{epoch} , loss: {loss.item()}')  # Use .item() to avoid memory leaks\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        print(f\"Invalid loss detected: {loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(Xs)    \n",
    "preds = preds.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ctc_loss(preds,yts,input_lengths,target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
